# 决策树/判断树（decision tree）

直观已于理解，小规模数据集有效
处理连续变量不好
类别较多时，错误率增加比较快
数据比较大时，计算量比较大
所有属性都是分类的，连续数据必须离散化

# K-最邻近算法（KNN k-nearest neighbors）

简单容易实现和理解，通过对K的选择可具备丢噪音数据的健壮性
需要大量空间存储已知实例（比较每个点的距离）
当样本分布不平衡时，比如其中一类样本过大，占主导的时候，新的未知实例容易被归类为这个主导样本。

# 支持向量机（SVM）

