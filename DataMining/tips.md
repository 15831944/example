# 机器学习算法

机器学习算法可以简单地分为4类：决策矩阵算法、聚类算法、模式识别算法和回归算法。

![https://github.com/dreamsxin/example/blob/master/DataMining/img/机器学习算法.jpg](https://github.com/dreamsxin/example/blob/master/DataMining/img/机器学习算法.jpg?raw=true)

## 非监督和监督算法

它们两者的区别在于学习的方式。

监督学习算法使用训练数据集学习，并且能够持续学习直到达到设定的置信水平（最小化出错概率）。监督学习算法分为回归、分类和异常检测以及数据降维。

无监督学习算法，则尝试挖掘有限数据的价值。这意味着，算法会在可用数据内建立关系，以检测模式或者将数据集分成子类（取决于之间的相似度）。从广义上，无监督算法可以可分为关联规则学习和聚类。

增强学习算法是另外一种机器学习算法，介于非监督学习和监督学习之间。对于所有训练的例子，监督学习中有目标标签，无监督学习中却完全没有标签。强化学习有延迟的、稀疏的标签——未来的奖励。

## 决策矩阵算法

决策矩阵算法系统地分析、识别和评估信息集和值之间关系的表现。这些算法主要用于决策。车是否需要刹车或者左转都是基于算法根据识别、分类和预测对象的下一个动作给出的置信水平。矩阵决策算法由各种独立训练的决策模型组合而成。用某种方式，这些预测整合起来进行总体预测，同时降低决策错误的可能性。AdaBoosting 是最常用的算法。

### AdaBoosting

Adaptive Boosting或称为AdaBoost，是一种多种学习算法的融合。它可用于回归或者分类算法。相比其他机器学习算法，它克服了过拟合，并通常对异常值和噪声数据敏感。为了创建一个强大的复合学习器，AdaBoost使用了多次迭代。因此，它又被称为 “Adaptive Boosting”。通过迭代添加弱学习器，AdaBoost创建了一个强学习器。一个新的弱学习器加到实体上，并且调整加权向量，作为对前一轮中错误分类的样例的回应。得到的结果，是一个比弱学习者分类器有更高准确性的分类器。

![https://github.com/dreamsxin/example/blob/master/DataMining/img/AdaBoosting.jpg](https://github.com/dreamsxin/example/blob/master/DataMining/img/AdaBoosting.jpg?raw=true)

AdaBoost有助于将弱阈值的分类器提升为强分类器。上面的图像描述了AdaBoost的执行，只用了简单易于理解的代码在一个文件中就实现了。这个函数包含一个弱分类器和boosting组件。弱分类器在一维的数据中尝试去寻找最理想的阈值来将数据分离为两类。boosting组件迭代调用分类器，经过每一步分类，它改变了错误分类示例的权重。因此，创建了一个级联的弱分类器，它的行为就像一个强分类器。

## 聚类算法

有时，系统获取的图片不是很清晰，使得物体难以定位检测。有时，分类算法有丢失检测物体的可能，这样就不能分类和报告给系统。这些可能是不连续的数据造成的，数据点太少了，或者图片分辨率太低了。聚类算法的特点在于从数据点中发现模式。像回归分析一样，聚类算法是指一类方法和问题。典型的聚类算法有层次聚类，基于质心的聚类算法。这些算法都关注数据的内在模式，完美地把数据分解成拥有最大相似性的簇。K-均值，多分类神经网络（Multi-class Neural Network）是最常用的算法。

### K-均值算法

K-均值是著名聚类算法，它找出代表聚类结构的k个质心。如果有一个点到某一质心的距离比到其他质心都近，这个点则指派到这个最近的质心所代表的簇。依次，利用当前已聚类的数据点找出一个新质心，再利用质心给新的数据指派一个簇。

![https://github.com/dreamsxin/example/blob/master/DataMining/img/K-均值算法.jpg](https://github.com/dreamsxin/example/blob/master/DataMining/img/K-均值算法.jpg?raw=true)

K-均值算法——在上图中用“x"表示 聚类质心，用点表示训练样本。(a) 原始数据集。(b) 随机初始化聚类质心。(c-f) k-均值迭代2次的示意图。在每次迭代中每个训练样例都指派到一个最近的聚类质心，每个聚类质心被移动到分配给它的点的平均值。

## 模式识别算法（分类模型）

在高级辅助驾驶系统（ADAS）中，利用感应器获取的图像包含各种各样的环境数据。对图像进行过滤变得十分必要，以剔除一些不相关的样本得到用于分类的实例数据。在分类前，关键步骤是在一个数据集上的模式识别。这类算法称为数据约简算法。

数据约简算法有助于降低数据集的边缘、对象的直线（拟合出来的线段）和圆弧的边缘。线段与边缘匹配，到直角后，该匹配会产生一段线段。和弧线一样，圆弧与一串直线段匹配。用不同的方式，图像特征（圆弧和线段）组合起来形成特征，用来判断对象。

利用PCA（主成分分析）和HOG（方向梯度直方图），SVM（支持向量机）通常在ADAS中用做识别算法。也会用K-邻近（KNN)和贝叶斯决策规则。

### 支持向量机（SVM)

SVM依赖于决策平面概念，后者定义了决策边界。决策平面可以把明显有类关系的对象分隔开. 如下图示。这张图片中，对象分为红色和绿色两类。分离的边界线把红色和绿色的对象分离了。落在线左边的新对象标记为红色类，落在右边标为绿色。

![https://github.com/dreamsxin/example/blob/master/DataMining/img/支持向量机.jpg](https://github.com/dreamsxin/example/blob/master/DataMining/img/支持向量机.jpg?raw=true)

## 回归算法

这类算法善于做事件预测。回归分析评估两个或两个以上变量的关系，以及变量在不同尺度上的贡献，主要受三个指标影响：

1、回归线的形状
2、非独立变量的类型
3、独立变量的数量

（摄像头或者雷达收集到的）图像在ADAS的驱动和定位上起了重要作用。对于任一算法，最大的挑战是利用基于图像的模型来做特征选择和预测。

环境的可重复性，对回归算法为图像和该图像中某物体位置之间的关系，构建统计模型起了杠杆作用。利用采样图像的统计模型，可以快速在线识别和离线学习。这个模型可以进一步延伸到不需要大量人类建模的其他对象。算法返回的对象位置，作为在线阶段的输出和对象出现的概率。

回归算法能够用来短程预测和长程训练。这类回归算法中用到自动驾驶上，有决策森林回归、神经网络回归、贝叶斯回归等等。

### 神经网络回归模型

神经网络可以用到回归、分类或者其他无监督学习上，来汇总没有标记的数据，分类这些数据，或者在监督学习后预测一个连续值。神经网络常在最后一层用逻辑斯特回归把连续值转换成形如1或0的变量（二值变量）。

![https://github.com/dreamsxin/example/blob/master/DataMining/img/神经网络回归模型.jpg](https://github.com/dreamsxin/example/blob/master/DataMining/img/神经网络回归模型.jpg?raw=true)

在上图中，“x”是输入，特征从前一层神经元传播而来。到最后隐藏层的每个神经元，有很多’x'会喂进来，每个'x',乘以相应的权重w。对于偏置，乘积求和后加上偏置，然后输入到激活函数。激活函数常用的是ReLU（修正线性单元），因为它不会像sigmoid激活函数在浅层梯度膨胀。ReLU在隐藏层输出的激活值a，经过求和后成为输出层的输出。这暗示：一个神经网络用做回归时只有一个输出节点。这个节点把激活值求和后乘以1向量。网络的估计值，‘y帕’作为结果。‘Y帕’是所有'x'映射出来的独立变量。你可以这样用神经网络得到与‘x’（多个非独立向量）相关的函数，可以求出你要预测的'y'(独立变量)。
